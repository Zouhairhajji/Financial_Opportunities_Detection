{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType, FloatType, TimestampType, DateType\n",
    "from pyspark.sql.functions import udf, dense_rank, desc, asc\n",
    "from pyspark.sql.functions import mean as _mean, min as _min, max as _max, sum as _sum, count as _count, datediff, to_date\n",
    "from pyspark.sql.functions import to_utc_timestamp, unix_timestamp, lit, datediff, col, date_format\n",
    "\n",
    "\n",
    "from pyspark.sql import functions as F, Row\n",
    "from pyspark.sql.functions import collect_set\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# web api\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen\n",
    "import urllib.parse as urlparse\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "\n",
    "from pylab import rcParams\n",
    "import math\n",
    "rcParams['figure.figsize'] = 15, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method that print only blanks\n",
    "def print_blanks(n=10):\n",
    "    for i in range(n):\n",
    "        print('\\n')\n",
    "\n",
    "# method that create connection with spark server\n",
    "def create_spark_context(master_ip='127.0.0.1'):\n",
    "    master_ip = 'spark://{}:7077'.format(master_ip)\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(master_ip)  \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    sc = spark.sparkContext\n",
    "    return (spark, sc)\n",
    "\n",
    "spark, sc = create_spark_context()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = '../ressources/data/financial_sells_100000.csv'\n",
    "csv_separator = ','\n",
    "\n",
    "\n",
    "# read csv file\n",
    "init_flat_data = spark.read         \\\n",
    "    .option(\"sep\", csv_separator)  \\\n",
    "    .csv(input_filename, header=True)\n",
    "\n",
    "company_names = init_flat_data \\\n",
    "    .select('company_id', 'company_name') \\\n",
    "    .distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_news(company_name):\n",
    "    url = 'https://news.google.com/news/rss/headlines/section/topic/BUSINESS?'\n",
    "    company_name = company_name # nom de l'entreprise\n",
    "    parameters = {\n",
    "        'q': company_name, # query phrase\n",
    "        'pageSize': 2, \n",
    "        'en': 'en' ,\n",
    "    }\n",
    "    \n",
    "    url = url + urlencode(parameters)\n",
    "\n",
    "    rss_reader = urlopen(url)\n",
    "    rss_data = rss_reader.read()\n",
    "    rss_reader.close()\n",
    "\n",
    "    soup_page = soup(rss_data, \"xml\")\n",
    "    news_list = soup_page.findAll(\"item\")\n",
    "    return news_list\n",
    "\n",
    "\n",
    "def analyse_company_reputation(company_id, company_name, _analyzer):\n",
    "    global_result = {\n",
    "        'company_id': company_id,\n",
    "        'company_name': company_name,\n",
    "        'negative': 0,\n",
    "        'positive': 0,\n",
    "        'neutre': 0,\n",
    "        'flag_gravity' : 0,\n",
    "        'flag': 'No Flag',\n",
    "        'neg_tweets' : []\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # parse all news\n",
    "    for news in get_company_news(company_name):\n",
    "        analyse_result = _analyzer.polarity_scores(news.title.text)\n",
    "        global_result['negative'] += analyse_result['neg']\n",
    "        global_result['positive'] += analyse_result['pos']\n",
    "        global_result['neutre'] += analyse_result['neu']\n",
    "\n",
    "        if(analyse_result['neg'] > 0.2):\n",
    "            global_result['neg_tweets'].append( news.title.text )\n",
    "    \n",
    "    flags = ['green', 'orange', 'red', 'red', 'red']\n",
    "    global_result['flag_gravity'] = int( global_result['negative'] / global_result['positive'] )\n",
    "    global_result['flag'] = flags[global_result['flag_gravity']]\n",
    "    \n",
    "    return global_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----+------------+--------------------+------------------+------+-----------------+\n",
      "|company_id|        company_name| flag|flag_gravity|          neg_tweets|          negative|neutre|         positive|\n",
      "+----------+--------------------+-----+------------+--------------------+------------------+------+-----------------+\n",
      "|        32|Ping An Insurance...|green|           0|Hong Kong shares ...|2.6679999999999997|87.903|9.427999999999999|\n",
      "+----------+--------------------+-----+------------+--------------------+------------------+------+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize sentimental analyze\n",
    "sentimental_analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "#udh method that convert array to string with  | as separator\n",
    "def_array2str = udf(lambda x: '|'.join(x), StringType())\n",
    "\n",
    "\n",
    "result_reputation = company_names \\\n",
    "    .rdd \\\n",
    "    .map(lambda x: Row(**analyse_company_reputation(x.company_id, x.company_name, sentimental_analyser)) ) \\\n",
    "    .toDF() \\\n",
    "    .withColumn('neg_tweets', def_array2str('neg_tweets'))\n",
    "\n",
    "result_reputation.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_reputation.coalesce(1) \\\n",
    "#    .write   \\\n",
    "#    .format(\"csv\") \\\n",
    "#    .mode('overwrite') \\\n",
    "#    .option(\"header\", \"true\") \\\n",
    "#    .save('./ressources/data/4_sentimental_analysis_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result in my postgresql database\n",
    "mode = \"overwrite\"\n",
    "table_name = 'algo_sentimental_analysis'\n",
    "url = \"jdbc:postgresql://127.0.0.1:5432/financial_opportunities\"\n",
    "properties = {\n",
    "    \"user\": \"zouhairhajji\",\n",
    "    \"password\": '',\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "result_reputation  \\\n",
    "        .write     \\\n",
    "        .jdbc(url=url, table=table_name, mode=mode, properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
